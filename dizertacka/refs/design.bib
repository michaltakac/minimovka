
@inproceedings{zuckermanDataSpoonOvercomingDesign2016,
	address = {Eindhoven, Netherlands},
	title = {{DataSpoon}: {Overcoming} {Design} {Challenges} in {Tangible} and {Embedded} {Assistive} {Technologies}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{DataSpoon}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839505},
	doi = {10.1145/2839462.2839505},
	abstract = {The design of tangible and embedded assistive technologies poses unique challenges. We describe the challenges we encountered during the design of "DataSpoon", explain how we overcame them, and suggest design guidelines. DataSpoon is an instrumented spoon that monitors movement kinematics during self-feeding. Children with motor disorders often encounter difficulty mastering selffeeding. In order to treat them effectively, professional caregivers need to assess their movement kinematics. Currently, assessment is performed through observations and questionnaires. DataSpoon adds sensor-based data to this process. A validation study showed that data obtained from DataSpoon and from a 6-camera 3D motion capture system were similar. Our experience yielded three design guidelines: needs of both caregivers and children should be considered; distractions to direct caregiver-child interaction should be minimized; familiar-looking devices may alleviate concerns associated with unfamiliar technology.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Zuckerman, Oren and Gal, Tamar and Keren-Capelovitch, Tal and Karsovsky, Tal and Gal-Oz, Ayelet and Weiss, Patrice L. Tamar},
	year = {2016},
	pages = {30--37},
	file = {Zuckerman et al. - 2016 - DataSpoon Overcoming Design Challenges in Tangibl.pdf:/Users/michaltakac/Zotero/storage/WY7ZASXA/Zuckerman et al. - 2016 - DataSpoon Overcoming Design Challenges in Tangibl.pdf:application/pdf}
}

@inproceedings{ohDesigningMultiuserInteractive2016,
	address = {Eindhoven, Netherlands},
	title = {Designing a {Multi}-user {Interactive} {Simulation} {Using} {AR} {Glasses}},
	isbn = {978-1-4503-3582-9},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2856521},
	doi = {10.1145/2839462.2856521},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Oh, Seungjae and Park, Kyudong and Kwon, Soonmo and So, Hyo-Jeong},
	year = {2016},
	pages = {539--544},
	file = {Oh et al. - 2016 - Designing a Multi-user Interactive Simulation Usin.pdf:/Users/michaltakac/Zotero/storage/5RGRUA8R/Oh et al. - 2016 - Designing a Multi-user Interactive Simulation Usin.pdf:application/pdf}
}

@inproceedings{spadaforaDesigningBehaviorInteractive2016,
	address = {Eindhoven, Netherlands},
	title = {Designing the {Behavior} of {Interactive} {Objects}},
	isbn = {978-1-4503-3582-9},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839502},
	doi = {10.1145/2839462.2839502},
	abstract = {To design proactive and autonomous interactive objects, designers deal with the design of the object’s behavior. In this paper, we propose a design method, called Personality, to help designers develop interactive objects’ behaviors with a focus on aesthetics of interaction; the method focuses on tangible and bodily interaction, and it includes four main steps. The “unguided improvisation” step consists of an initial interplay with the interactive object in order to size up the interaction; a brainstorming step, in which we use stereotypes of personalities to create metaphors, to support the discussion around, and the description of, possible behaviors; the “guided improvisation” step iterates over several improvisation sessions to act out interaction scenarios and behaviors; and the behavior synthesis step, in which we provide a final description of the object’s behavior. To illustrate Personality we will describe the sofa-bot case study. We will report a lab study, in which we observed people reaction to the different behaviors of the sofa.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Spadafora, Marco and Chahuneau, Victor and Martelaro, Nikolas and Sirkin, David and Ju, Wendy},
	year = {2016},
	pages = {70--77},
	file = {Spadafora et al. - 2016 - Designing the Behavior of Interactive Objects.pdf:/Users/michaltakac/Zotero/storage/D4IHEVUB/Spadafora et al. - 2016 - Designing the Behavior of Interactive Objects.pdf:application/pdf}
}

@inproceedings{smitIdeatingSkillsDeveloping2016,
	address = {Eindhoven, Netherlands},
	title = {Ideating in {Skills}: {Developing} {Tools} for {Embodied} {Co}-{Design}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {Ideating in {Skills}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839497},
	doi = {10.1145/2839462.2839497},
	abstract = {In this paper, we show the development of the Ideating in Skills (IiS) toolset: an embodied design tool aimed at supporting co-design processes. The iterative process of developing the toolset was carried out by students. They worked individually at first, exploring their own skills and moods through movement, visualisations and poetry. These explorations were translated into objects that were able to communicate and connect with each other. In each iteration, the design of the qualities of these connections was based on the findings of the previous explorations. After several individual and team-based iterations, a final toolset was collaboratively created and evaluated in various short design sessions. Based on the potential of the first version of the toolset, a second version was created that is currently used and tested in one-on-one settings all over the world and in multi-stakeholder settings in a creative hub in Sweden.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Smit, Dorothé and Oogjes, Doenja and de Rocha, Bruna Goveia and Trotto, Ambra and Hur, Yeup and Hummels, Caroline},
	year = {2016},
	pages = {78--85},
	file = {Smit et al. - 2016 - Ideating in Skills Developing Tools for Embodied .pdf:/Users/michaltakac/Zotero/storage/XWP9R5UT/Smit et al. - 2016 - Ideating in Skills Developing Tools for Embodied .pdf:application/pdf}
}

@inproceedings{rooInnerGardenAugmented2016,
	address = {Eindhoven, Netherlands},
	title = {Inner {Garden}: an {Augmented} {Sandbox} {Designed} for {Self}-{Reflection}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {Inner {Garden}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2856532},
	doi = {10.1145/2839462.2856532},
	abstract = {We present a prototype of an augmented sandbox where the sand is used to create a miniature living world, designed as an ambient display for contemplation and selfreﬂection. The landscape can be reshaped at any time. Once the sand is left still for a moment, the world starts evolving – vegetation grows, water ﬂows and creatures move around – according to the user’s internal state. We use a consumer-grade EEG and breathing sensors to reﬂect on frustration and meditative states of users, which they can monitor by looking at the sandbox.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Roo, Joan Sol and Gervais, Renaud and Hachet, Martin},
	year = {2016},
	pages = {570--576},
	file = {Roo et al. - 2016 - Inner Garden an Augmented Sandbox Designed for Se.pdf:/Users/michaltakac/Zotero/storage/9DWQB7CD/Roo et al. - 2016 - Inner Garden an Augmented Sandbox Designed for Se.pdf:application/pdf}
}

@inproceedings{versteegInteractiveJewelleryDesign2016,
	address = {Eindhoven, Netherlands},
	title = {Interactive {Jewellery}: a design exploration},
	isbn = {978-1-4503-3582-9},
	shorttitle = {Interactive {Jewellery}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839504},
	doi = {10.1145/2839462.2839504},
	abstract = {Many current wearables have a technology-driven background: the focus is primarily on functionality, while their possible personal and social-cultural value is underappreciated. We think that developing wearables from a jewellery perspective can compensate for this. The personal and social cultural values embodied by traditional jewellery are often tightly connected to their function as memento. In this paper we reflect from a jewellery perspective, a memory-studies perspective and a TEI-perspective on three design proposals for interactive jewellery. We identify 1) drawing inspiration from interaction with traditional jewellery, 2) using relatively simple technology with high experiential qualities, 3) abstract and poetic data representation and 4) storing data uniquely on the digital jewel as possible design directions.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Versteeg, Maarten and van den Hoven, Elise and Hummels, Caroline},
	year = {2016},
	pages = {44--52},
	file = {Versteeg et al. - 2016 - Interactive Jewellery a design exploration.pdf:/Users/michaltakac/Zotero/storage/E7UPKP8X/Versteeg et al. - 2016 - Interactive Jewellery a design exploration.pdf:application/pdf}
}

@inproceedings{yuLivingSurfaceBiofeedbackShapechanging2016,
	address = {Eindhoven, Netherlands},
	title = {{LivingSurface}: {Biofeedback} through {Shape}-changing {Display}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{LivingSurface}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839469},
	doi = {10.1145/2839462.2839469},
	abstract = {In this paper we describe the concept, design and implementation of LivingSurface, an interactive wall-like surface as a shape-changing display of biofeedback. The surface changes its shape responding to an individual’s physiological data, reflecting the internal bodily processes. The surface design basically consists of two layers: the pattern layer (front layer) and the actuating layer (back layer). The first is a complex paper-based structure with repetitive incisions created by laser cutting. The actuating layer serves as a medium transforming the force from servomotors, vibration motors or fans into an action on the pattern layer. The cutout patterns are stimulated to vibrate, swing, bulge, or rotate which is used to display physiological information in dynamic physical form. This work has been exhibited on Milan Design Week 2015; we collected and analyzed the feedback from the visitors during the exhibition and discuss the possibilities of the proposed surfaces as a shape-changing interface of biofeedback or an ambient display of information.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Yu, Bin and Bongers, Nienke and van Asseldonk, Alissa and Hu, Jun and Funk, Mathias and Feijs, Loe},
	year = {2016},
	pages = {168--175},
	file = {Yu et al. - 2016 - LivingSurface Biofeedback through Shape-changing .pdf:/Users/michaltakac/Zotero/storage/IXWE6ND4/Yu et al. - 2016 - LivingSurface Biofeedback through Shape-changing .pdf:application/pdf}
}

@inproceedings{vijayMagnetoWearMagneticWearable2016,
	address = {Eindhoven, Netherlands},
	title = {{MagnetoWear}: {A} {Magnetic} {Wearable} {Device} to {Interact} {With} the {Smartphone} to {Perform} {Personalized} {Actions}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{MagnetoWear}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2856554},
	doi = {10.1145/2839462.2856554},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Vijay, Rohan S. and Goyal, Sidhant},
	year = {2016},
	pages = {597--602},
	file = {Vijay and Goyal - 2016 - MagnetoWear A Magnetic Wearable Device to Interac.pdf:/Users/michaltakac/Zotero/storage/TUW8WEN3/Vijay and Goyal - 2016 - MagnetoWear A Magnetic Wearable Device to Interac.pdf:application/pdf}
}

@inproceedings{vinayakMobiSweepExploringSpatial2016,
	address = {Eindhoven, Netherlands},
	title = {{MobiSweep}: {Exploring} {Spatial} {Design} {Ideation} {Using} a {Smartphone} as a {Hand}-held {Reference} {Plane}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{MobiSweep}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839490},
	doi = {10.1145/2839462.2839490},
	abstract = {In this paper, we explore quick 3D shape composition during early-phase spatial design ideation. Our approach is to re-purpose a smartphone as a hand-held reference plane for creating, modifying, and manipulating 3D sweep surfaces. We implemented MobiSweep, a prototype application to explore a new design space of constrained spatial interactions that combine direct orientation control with indirect position control via well-established multi-touch gestures. MobiSweep leverages kinesthetically aware interactions for the creation of a sweep surface without explicit position tracking. The design concepts generated by users, in conjunction with their feedback, demonstrate the potential of such interactions in enabling spatial ideation.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {{Vinayak} and Ramanujan, Devarajan and Piya, Cecil and Ramani, Karthik},
	year = {2016},
	pages = {12--20},
	file = {Vinayak et al. - 2016 - MobiSweep Exploring Spatial Design Ideation Using.pdf:/Users/michaltakac/Zotero/storage/3422WTCD/Vinayak et al. - 2016 - MobiSweep Exploring Spatial Design Ideation Using.pdf:application/pdf}
}

@inproceedings{hemmertOtherHandEmbodied2016,
	address = {Eindhoven, Netherlands},
	title = {On the {Other} {Hand}: {Embodied} {Metaphors} for {Interactions} with {Mnemonic} {Objects} in {Live} {Presentations}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {On the {Other} {Hand}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839470},
	doi = {10.1145/2839462.2839470},
	abstract = {We describe a presentation system based on the embodied metaphors of giving presentations: topics are picked up, one goes through a series of points, and comes to a conclusion. Technically, our system is based on body tracking and handworn RFID readers. Wearing these readers, users can activate topics in live presentations by picking up RFID-tagged mnemonic objects. Each topic can consist of multiple points, which are mapped to positions on stage. Users can activate a point (and its corresponding slide) by walking up to its position on stage. Various actions, triggered by constellations of handheld objects and movements on stage, are supported by the system. We conducted a series of informal user feedback sessions. Its results indicate that our system has strengths and weaknesses, depending on presenter style and presentation context.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Hemmert, Fabian and Joost, Gesche},
	year = {2016},
	pages = {211--217},
	file = {Hemmert and Joost - 2016 - On the Other Hand Embodied Metaphors for Interact.pdf:/Users/michaltakac/Zotero/storage/7PJZ3TJI/Hemmert and Joost - 2016 - On the Other Hand Embodied Metaphors for Interact.pdf:application/pdf}
}

@inproceedings{vianelloT4TagsTangibleSystem2016,
	address = {Eindhoven, Netherlands},
	title = {{T4Tags} 2.0: {A} {Tangible} {System} for {Supporting} {Users}' {Needs} in the {Domestic} {Environment}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{T4Tags} 2.0},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839479},
	doi = {10.1145/2839462.2839479},
	abstract = {The use of dedicated devices may insufficiently support the variety and subtlety of domestic arrangements: they usually focus on specific aspects (e.g., home automation, health, safety, etc.) and potentially become obsolete, since they are unable to be recomposed and adapted to the needs of new situations. Open-ended and repurposable technologies could better address domestic users’ needs. We present T4Tags 2.0, an open-ended toolkit for programming tangible tokens that embed different sensing technologies and can be attached to ordinary objects to create smart behaviors at home. We report findings from a one-day workshop we carried out to explore opportunities of the toolkit.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Vianello, Andrea and Florack, Yves and Bellucci, Andrea and Jacucci, Giulio},
	year = {2016},
	pages = {38--43},
	file = {Vianello et al. - 2016 - T4Tags 2.0 A Tangible System for Supporting Users.pdf:/Users/michaltakac/Zotero/storage/NBA4VWA2/Vianello et al. - 2016 - T4Tags 2.0 A Tangible System for Supporting Users.pdf:application/pdf}
}

@inproceedings{gervaisTangibleViewportsGetting2016,
	address = {Eindhoven, Netherlands},
	title = {Tangible {Viewports}: {Getting} {Out} of {Flatland} in {Desktop} {Environments}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {Tangible {Viewports}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839468},
	doi = {10.1145/2839462.2839468},
	abstract = {Spatial augmented reality and tangible interaction enrich the standard computer I/O space. Systems based on such modalities offer new user experiences and open up interesting perspectives in various ﬁelds. On the other hand, such systems tend to live outside the standard desktop paradigm and, as a consequence, they do not beneﬁt from the richness and versatility of desktop environments. In this work, we propose to join together physical visualization and tangible interaction within a standard desktop environment. We introduce the concept of Tangible Viewport, an on-screen window that creates a dynamic link between augmented objects and computer screens, allowing a screen-based cursor to move onto the object in a seamless manner. We describe an implementation of this concept and explore the interaction space around it. A preliminary evaluation shows the metaphor is transparent to the users while providing the beneﬁts of tangibility.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Gervais, Renaud and Roo, Joan Sol and Hachet, Martin},
	year = {2016},
	pages = {176--184},
	file = {Gervais et al. - 2016 - Tangible Viewports Getting Out of Flatland in Des.pdf:/Users/michaltakac/Zotero/storage/AVHLYZ3J/Gervais et al. - 2016 - Tangible Viewports Getting Out of Flatland in Des.pdf:application/pdf}
}

@inproceedings{molsTechnologiesEverydayLife2016,
	address = {Eindhoven, Netherlands},
	title = {Technologies for {Everyday} {Life} {Reflection}: {Illustrating} a {Design} {Space}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {Technologies for {Everyday} {Life} {Reflection}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839466},
	doi = {10.1145/2839462.2839466},
	abstract = {Reflection gives insight, supports action and can improve wellbeing. People might want to reflect more often for these benefits, but find it difficult to do so in everyday life. Research in HCI has shown the potential of systems to support reflection in different contexts. In this paper we present a design space for supporting everyday life reflection. We produced a workbook with a selection of conceptual design proposals, which show how systems can take different roles in the process of reflection: triggering, supporting and capturing. We describe a design space with two dimensions by combining these roles with strategies found in literature. We contribute to the extensive body of work on reflection by outlining how design for everyday life reflection requires a focus on more holistic reflection, design with openness and integration in everyday life.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Mols, Ine and van den Hoven, Elise and Eggen, Berry},
	year = {2016},
	pages = {53--61},
	file = {Mols et al. - 2016 - Technologies for Everyday Life Reflection Illustr.pdf:/Users/michaltakac/Zotero/storage/SALRYGXS/Mols et al. - 2016 - Technologies for Everyday Life Reflection Illustr.pdf:application/pdf}
}

@inproceedings{yoonTMotionEmbedded3D2016,
	address = {Eindhoven, Netherlands},
	title = {{TMotion}: {Embedded} {3D} {Mobile} {Input} using {Magnetic} {Sensing} {Technique}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{TMotion}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839463},
	doi = {10.1145/2839462.2839463},
	abstract = {We present TMotion, a self-contained 3D input that enables spatial interactions around mobile device using a magnetic sensing technique. We embed a permanent magnet and an inertial measurement unit (IMU) in a stylus. When the stylus moves around the mobile device, we obtain a continuous magnetometer readings. By numerically solving non-linear magnetic ﬁeld equations with known orientation from IMU, we achieve 3D position tracking with update rate greater than 30Hz. Our experiments evaluated the position tracking accuracy, showing an average error of 4.55mm in the space of 80mm⇥120mm⇥100mm. Furthermore, the experiments conﬁrmed the tracking robustness against orientations and dynamic tracings. In task evaluations, we veriﬁed the tracking and targeting performance in spatial interactions with users. We demonstrate example applications that highlight TMotion’s interaction capability.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Yoon, Sang Ho and Huo, Ke and Ramani, Karthik},
	year = {2016},
	pages = {21--29},
	file = {Yoon et al. - 2016 - TMotion Embedded 3D Mobile Input using Magnetic S.pdf:/Users/michaltakac/Zotero/storage/CLX43XLK/Yoon et al. - 2016 - TMotion Embedded 3D Mobile Input using Magnetic S.pdf:application/pdf}
}

@inproceedings{gervaisTOBETangibleOutofBody2016,
	address = {Eindhoven, Netherlands},
	title = {{TOBE}: {Tangible} {Out}-of-{Body} {Experience}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{TOBE}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839486},
	doi = {10.1145/2839462.2839486},
	abstract = {We propose a toolkit for creating Tangible Out-of-Body Experiences: exposing the inner states of users using physiological signals such as heart rate or brain activity. Tobe can take the form of a tangible avatar displaying live physiological readings to reﬂect on ourselves and others. Such a toolkit could be used by researchers and designers to create a multitude of potential tangible applications, including (but not limited to) educational tools about Science Technologies Engineering and Mathematics (STEM) and cognitive science, medical applications or entertainment and social experiences with one or several users or Tobes involved. Through a co-design approach, we investigated how everyday people picture their physiology and we validated the acceptability of Tobe in a scientiﬁc museum. We also give a practical example where two users relax together, with insights on how Tobe helped them to synchronize their signals and share a moment.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Gervais, Renaud and Frey, Jérémy and Gay, Alexis and Lotte, Fabien and Hachet, Martin},
	year = {2016},
	pages = {227--235},
	file = {Gervais et al. - 2016 - TOBE Tangible Out-of-Body Experience.pdf:/Users/michaltakac/Zotero/storage/94D6F8HG/Gervais et al. - 2016 - TOBE Tangible Out-of-Body Experience.pdf:application/pdf}
}

@inproceedings{harleyFrameworkTangibleNarratives2016,
	address = {Eindhoven, Netherlands},
	title = {Towards a {Framework} for {Tangible} {Narratives}},
	isbn = {978-1-4503-3582-9},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839471},
	doi = {10.1145/2839462.2839471},
	abstract = {This paper presents a preliminary framework to inform the analysis and design of tangible narratives. Researchers and designers have been using tangible user interfaces (TUIs) for storytelling over the past two decades, but to date no comprehensive analysis of these systems exists. We argue that storytelling systems that use digitally-enhanced physical objects form a unique medium with identifiable narrative characteristics. Our framework isolates these characteristics and focuses on the user's perspective to identify commonalities between existing systems, as well as gaps that can be addressed by new systems. We find that the majority of systems in our sample require the user to perform exploratory actions from an external narrative position. We note that systems that cast the user in other interactive roles are rare but technologically feasible, suggesting that there are many underexplored possibilities for tangible storytelling.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Harley, Daniel and Chu, Jean Ho and Kwan, Jamie and Mazalek, Ali},
	year = {2016},
	pages = {62--69},
	file = {Harley et al. - 2016 - Towards a Framework for Tangible Narratives.pdf:/Users/michaltakac/Zotero/storage/X5ZQN7M6/Harley et al. - 2016 - Towards a Framework for Tangible Narratives.pdf:application/pdf}
}

@inproceedings{kosakaUnicrePaintDigitalPainting2016,
	address = {Eindhoven, Netherlands},
	title = {{UnicrePaint}: {Digital} {Painting} through {Physical} {Objects} for {Unique} {Creative} {Experiences}},
	isbn = {978-1-4503-3582-9},
	shorttitle = {{UnicrePaint}},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2856553},
	doi = {10.1145/2839462.2856553},
	abstract = {Mankind’s capacity for creativity is inﬁnite. In the physical world, people create visual artistic works not only with speciﬁc tools, such as paintbrushes, but also with various objects, such as dried ﬂowers pressed on paper. In contrast, digital painting has a number of advantages; however, such painting currently requires a speciﬁc tool, such as a stylus, which might diminish the pleasurable experience of creation. This paper proposes a digital painting system called UnicrePaint that utilizes daily objects as tools of expression and demonstrates the capabilities of the ﬁrst prototype system with a pilot user study.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Kosaka, Mami and Fujinami, Kaori},
	year = {2016},
	pages = {475--481},
	file = {Kosaka and Fujinami - 2016 - UnicrePaint Digital Painting through Physical Obj.pdf:/Users/michaltakac/Zotero/storage/XDHFHM6X/Kosaka and Fujinami - 2016 - UnicrePaint Digital Painting through Physical Obj.pdf:application/pdf}
}

@inproceedings{marshallUsingTangibleSmart2016,
	address = {Eindhoven, Netherlands},
	title = {Using {Tangible} {Smart} {Replicas} as {Controls} for an {Interactive} {Museum} {Exhibition}},
	isbn = {978-1-4503-3582-9},
	url = {http://dl.acm.org/citation.cfm?doid=2839462.2839493},
	doi = {10.1145/2839462.2839493},
	abstract = {This paper presents the design, creation and use of tangible smart replicas in a large-scale museum exhibition. We describe the design rationale for the replicas, the process used in their creation, as well as the implementation and deployment of these replicas in a live museum exhibition. Deployment of the exhibition resulted in over 14000 visitors interacting with the system during the 6 months that the exhibition was open. Based on log data, interviews and observations, we examine the reaction to these smart replicas from the point of view of the museum curators and also of the museum’s visitors and reflect on the fulfillment of our expectations.},
	language = {en},
	urldate = {2018-09-24},
	booktitle = {Proceedings of the {TEI} '16: {Tenth} {International} {Conference} on {Tangible}, {Embedded}, and {Embodied} {Interaction} - {TEI} '16},
	publisher = {ACM Press},
	author = {Marshall, Mark T. and Dulake, Nick and Ciolfi, Luigina and Duranti, Daniele and Kockelkorn, Hub and Petrelli, Daniela},
	year = {2016},
	pages = {159--167},
	file = {Marshall et al. - 2016 - Using Tangible Smart Replicas as Controls for an I.pdf:/Users/michaltakac/Zotero/storage/7DCSMSJY/Marshall et al. - 2016 - Using Tangible Smart Replicas as Controls for an I.pdf:application/pdf}
}
