\setcounter{page}{1}
\setcounter{equation}{0}
\setcounter{figure}{0}
\setcounter{table}{0}

\section{Introduction}

The objective of process control is to keep key process-operating parameters within narrow bounds of the reference value or setpoint. Controllers are used to automate a human function in an effort to control a variable. A basic controller can keep an individual loop on an even point, so long as there is not too much disruption. Complex processes like ones in metallurgy might employ dozens or even hundreds of such controllers, but keeping an~eye on the big picture was, until not so long ago, a human process.

Although a device was used to automate a human function in an effort to control a variable, there was no sense of what the process was doing overall. A basic controller could keep an individual loop on an even keel, more or less, so long as there was not too much disruption. Complex processes might employ dozens or even hundreds of such controllers, each with its performance displayed on a panel board, but keeping an eye on the big picture was still a human process.	

When distributed control system (DCS) platforms were introduced in the 1970s, they simplified the mechanics of the panel board, but did not do much to improve its capabilities. Big-picture analysis was still largely a human responsibility. Sure, getting beyond the technical constraints of pneumatic field devices with their troublesome compressed air tubing made it easier to install more instruments and actuators, but the basic control concepts did not really change. Any movement to advanced process control (APC) and other forms of control optimization were still in their infancy. Process automation capable of supporting APC had to encompass many technologies and techniques. It was characterized by incorporating many more input data points into algorithms and orchestrating more complex sequences.

The transition to process automation and advanced process control (APC) was empowered by being able to create an all-encompassing platform capable of coordinating more than single loops or small cascade groups. One major advantage of newer platforms is the ability to optimize a process to suit the owner’s specific economic goals based on~any number of desired outcomes. The process automation system can operate the plant to minimize energy consumption, maximize output, and deliver specific product quality attributes.

Implementing such systems is challenging. During the initial design phase of a control system upgrade or a new installation, it is far too easy to focus just on process fundamentals, and never get beyond considering desired steady-state conditions. Automation system upgrades and new installations can therefore miss opportunities to engage with process and automation technology experts capable of uncovering better ways of doing things. Many capabilities of modern process automation systems are still underutilized in most process plants. Far fewer companies use APC as effectively as they could, even though basic APC technologies have been around for decades.

Peter Drucker, a well-known management thinker, who has been quoted multiple times over the years by various people, has famously said: “If you can't measure it, you can't manage it. If you can't manage it, you can't improve it.” His words are now resonating more than ever with the push towards Industry 4.0. New trends like smart sensors, parallel computing for fluid dynamics simulations and virtual reality are getting traction and they found useful applications in metallurgy field, especially in production processes. Roadmap for implementing Industry 4.0 solutions into practice is being pushed around the world and we can feel it happening intensely in Europe region as well. Integrating them into already established plants is not coming without big considerations and analyses of potential economic benefits. Employing smart sensors that can gather and generate multiple-times more data means we must also employ more efficient algorithms for processing these large amounts of data. Data sets on the steelmaking process were available before, however the innovations of the fourth industrial revolution are opening new conceivable outcomes that permit steel makers to gather more information in various manners from myriad of smart sensors and smart systems that communicate over a local network. The term "Big Data" refers to this phenomenon of increasing complexity that it’s difficult or impossible to process using traditional methods and also volume and velocity of data acquisition we now see regularly with upcoming fourth industrial revolution. Big Data means the analysis of large amounts of data coming from different sources with high speed and with the aim to create economic benefit.

The goal of this disseration is to encompass applications of selected procedures that fall under the umbrella term Industry 4.0 in metallurgy field, specifically in basic oxygen steelmaking process (BOP), by connecting latest research in process control, mathematical modeling, numerical simulation, computational fluid dynamics, visualization and virtual reality. With combined expertise from my work in software engineering, 3D modeling and virtual reality visualizations with research work done by colleagues at Institute of Control and Informatization of Production Processes, novel immersive virtual reality environment for studying basic oxygen steelmaking processes will be designed and implemented. Objectives of the dissertation will be discussed in section \ref{section:3}. I find it useful to focus specifically on this area as I have access to good research opportunities in my region (U.S.Steel in Košice, V\"{o}estalpine in Linz), and last, but not least, BOP is one of two major commercial processes for making steel (other being electric arc furnace).